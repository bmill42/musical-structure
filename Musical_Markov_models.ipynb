{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjlYK0FTPXpHDfSWG9Xixa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bmill42/musical-structure/blob/main/Musical_Markov_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "dHjdjxUhIz5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install music21 --quiet\n",
        "!pip install midi_player --quiet"
      ],
      "metadata": {
        "id": "VW7yrXUWxdgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "732n5rYpfmL2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import music21\n",
        "from midi_player import MIDIPlayer\n",
        "from midi_player.stylers import basic, cifka_advanced\n",
        "from fractions import Fraction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll work with a range of pitches covering three octaves, from one octave below middle C (MIDI note 60) to two octaves above. I'll explain the full notation for this later, but this code helps map our representation to MIDI numbers."
      ],
      "metadata": {
        "id": "bn3GsSZJJHNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "octave_map = { '-': 48, '=': 60, '+': 72 }\n",
        "\n",
        "scale_deg_map = { '1': 0, '2': 2, '3': 4, '4': 5, '5': 7, '6': 9, '7': 11 }\n",
        "\n",
        "def scale_degree_to_num(deg):\n",
        "    return octave_map[deg[0]] + scale_deg_map[deg[1]]"
      ],
      "metadata": {
        "id": "JNzwzKXMyTuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_to_string(tune, dur=1, wait=1, rhythms=None):\n",
        "    pitches = tune.split(' ')\n",
        "    if rhythms is None:\n",
        "        return ' '.join(['n_{}_{} w_{}.0'.format(str(scale_degree_to_num(p)), dur, wait) for p in pitches])\n",
        "    else:\n",
        "        pitch_rhythms = zip(pitches, rhythms)\n",
        "        return ' '.join(['n_{}_{} w_{}'.format(str(scale_degree_to_num(pr[0])), pr[1], pr[1]) for pr in pitch_rhythms])\n",
        "\n",
        "def string_to_midi(tune, dur=1, wait=1, rhythms=None):\n",
        "    s = tune_to_string(tune, dur, wait, rhythms)\n",
        "    stream = music21.stream.Stream()\n",
        "    time = 1\n",
        "    for i in s.split():\n",
        "        if i.startswith('n'):\n",
        "            note, duration = i.lstrip('n_').split('_')\n",
        "            n = music21.note.Note(int(note))\n",
        "            n.duration.quarterLength = float(duration)\n",
        "            stream.insert(time, n)\n",
        "        elif i.startswith('w'):\n",
        "            time += float(Fraction(i.lstrip('w_')))\n",
        "    return stream\n",
        "\n",
        "def play_midi(tune, dur=1, wait=1, rhythms=None):\n",
        "    midi = string_to_midi(tune, dur, wait, rhythms)\n",
        "    midi.write('midi', 'generated.midi')\n",
        "    return MIDIPlayer('generated.midi', 120, styler=cifka_advanced, title='My Player', width='50%')"
      ],
      "metadata": {
        "id": "Uyo2rzIvxlPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Markov model with random weights"
      ],
      "metadata": {
        "id": "DZohBznkxl5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before refining it later, we're going to set up a Markov model based on diatonic scale degrees with random transition probabilities.\n",
        "\n",
        "First, let's set up a \"keyboard\" notation that captures all seven diatonic scale degrees with an octave indicator: `-` for a low octave, `=` for the middle octave, and `+` for a high octave. We can think of each item in the `keyboard` list as a white key on the piano."
      ],
      "metadata": {
        "id": "642sdAOPgVaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diatonic_scale_degrees = [str(i) for i in range(1,8)]\n",
        "octaves = ['-', '=', '+']\n",
        "\n",
        "keyboard = [o + p for o in octaves for p in diatonic_scale_degrees]"
      ],
      "metadata": {
        "id": "6kbinh0Cr-Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \"Training\" the model\n",
        "\n",
        "Whereas previously we built a model by keeping a list of all the words that followed any given word in the Shakespeare corpus---which let us simply choose  a word at random to generate new sentences---this time we will represent the model as an explicit set of probabilities.\n",
        "\n",
        "Here's the basic structure: the keys in the top-level dictionary represent the current state of the model, and the keys in the sub-dictionary represent the different possible following states.\n",
        "\n",
        "```\n",
        "{\n",
        "    '1': {\n",
        "        '1': 2,\n",
        "        '2': 5,\n",
        "        '3': 3,\n",
        "    },\n",
        "    '2': {\n",
        "        '1': 5,\n",
        "        '2': 1,\n",
        "        '3': 4\n",
        "    },\n",
        "    ...\n",
        "}\n",
        "```\n",
        "\n",
        "The values in the sub-dictionary are **weights**. They work like percentages: larger values represent a higher chance of that state being chosen next. But they don't need to add up to one or even be decimal values---we'll use a method that automatically adds up the weights and turns them into a percentage.\n",
        "\n",
        "For example, if the current state was '1', the chance of moving to '2' would be `5 / (2 + 5 + 3) = 0.5`\n",
        "\n",
        "To generate a fully randomized model, we just need to add every note from our keyboard to the dictionary, and for each note we build a sub-dictionary that also contains every note, with a random value between 0 and 10.\n",
        "\n",
        "We'll also follow the convention from the text model where `'START'` and `'END'` states control how generated sequences begin and end. Every single state can potentially lead to an `'END'` token, but we'll constrain `'START'` somewhat: only scale degrees 3 and 5 can begin the melody."
      ],
      "metadata": {
        "id": "dhty6dknKib5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = dict()\n",
        "\n",
        "for k in keyboard:\n",
        "    model[k] = dict()\n",
        "    for j in keyboard:\n",
        "        model[k][j] = random.randint(0, 10)\n",
        "    model[k]['END'] = 10\n",
        "\n",
        "model['START'] = {\n",
        "    '=3': 1,\n",
        "    '=5': 1\n",
        "}"
      ],
      "metadata": {
        "id": "VLowV6dTsJm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's peek inside and see what the weights look like for scale degree 1 in the middle octave:"
      ],
      "metadata": {
        "id": "w2bOfeyePyru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model['=1']"
      ],
      "metadata": {
        "id": "jCSjxLDHt_AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating new tokens\n",
        "\n",
        "We need a new method to generate tokens, since we can't just choose a random token from a list built from the corpus anymore. Instead, we need to sum all the weights and use those to choose the next state.\n",
        "\n",
        "The `random.choices()` function does exactly this by taking a list of the possible states and a list of the weights. See the docs if you're interested in how it works.\n",
        "\n",
        "Our `generate()` function is almost identical to the one from the text model."
      ],
      "metadata": {
        "id": "36HTvhXiQKE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def next_state(model, cur_state):\n",
        "    return random.choices(population=list(model[cur_state].keys()), weights=list(model[cur_state].values()), k=1)[0]\n",
        "\n",
        "def generate(model):\n",
        "    output = ''\n",
        "    pitch = next_state(model, 'START')\n",
        "\n",
        "    while pitch != 'END':\n",
        "        output += pitch + ' '\n",
        "        pitch = next_state(model, pitch)\n",
        "\n",
        "    return output.strip()"
      ],
      "metadata": {
        "id": "pTuDn5SsgqI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can test the generator out by providing it with the model and any valid state."
      ],
      "metadata": {
        "id": "kuT0NCruRDBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_state(model, '=1')"
      ],
      "metadata": {
        "id": "B0ZPYT3cgrCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running `generate()` will give us a full tune beginning with `'START'` and finishing when it hits an `'END'` state."
      ],
      "metadata": {
        "id": "LUlUsj6sRQ8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_tune = generate(model)\n",
        "new_tune"
      ],
      "metadata": {
        "id": "cvI_tVJhh9uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result may or may not sound slightly more tuneful than the 12-tone rows we generated previously---still pretty random, with a lot of awkward leaps."
      ],
      "metadata": {
        "id": "oppbaCz-Rgg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "play_midi(new_tune)"
      ],
      "metadata": {
        "id": "zQKihmm-pb8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: Markov model with custom weights"
      ],
      "metadata": {
        "id": "aEWq0VnN39eU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your assignment is to build your own custom model by entering your own weights for the various scale degrees.\n",
        "\n",
        "**Fill out this dictionary with new weights derived from the example transcriptions of Mitski and Taylor Swift.** Specifically, build one **verse model** and one **chorus model**, using the combined scale degree transition probabilities from the two songs we used as examples in class.\n",
        "\n",
        "You can either calculate the probabilities by hand by counting the transitions for each scale degree or you can represent the melodies in a form that allows you to calculate the probabilities automatically (the code from the Shakespeare Markov model could be helpful here).\n",
        "\n",
        "You must have `'START'` and `'END'` tokens, and you should use them strategically: `'START'` should lead to reasonable starting notes and melodies should typically `'END'` after reaching scale degree 1."
      ],
      "metadata": {
        "id": "tfD4T5boVtJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verse_model = {\n",
        "    # create the model here\n",
        "}\n",
        "chorus_model = {\n",
        "    # create the model here\n",
        "}"
      ],
      "metadata": {
        "id": "Z1MWH7ac0y-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Once your model dictionary is finished,** uncomment and run the following cells to view and hear the melodies you generate."
      ],
      "metadata": {
        "id": "CXDzSQ0lSfen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#custom_verse = generate(verse_model)\n",
        "\n",
        "#print(custom_verse)\n",
        "#play_midi(custom_verse)"
      ],
      "metadata": {
        "id": "GMa1vWcTSJfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#custom_chorus = generate(chorus_model)\n",
        "\n",
        "#print(custom_chorus)\n",
        "#play_midi(custom_chorus)"
      ],
      "metadata": {
        "id": "tDTnndyNSPp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: Markov model with pitch and rhythm"
      ],
      "metadata": {
        "id": "f5ed2fl13_10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our melodies will be more convincing if we give them more varied rhythms. Rhythm can be incorporated directly into the initial model by associating it with the tokens from the beginning (or by training on a corpus that include duration information, like ABC notation), but we'll generate durations for our notes separately and apply them at playback.\n",
        "\n",
        "We'll represent durations as numbers, with 1 representing the duration of the notes we've seen so far in the MIDI player. A duration of 0.5 is half as long, 2 is twice as long, etc.\n",
        "\n",
        "We can generate rhythms entirely randomly by using `random.choice()` once for each element in the tune we already generated. The `play_midi()` function already knows how to add rhythms to tunes, so we can just add the list of durations as an argument."
      ],
      "metadata": {
        "id": "xebsxB40UeKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "durations = [0.5, 1, 2, 3, 4]\n",
        "tune_rand_rhythm = [random.choice(durations) for i in range(len(new_tune.split(' ')))]"
      ],
      "metadata": {
        "id": "kmR9vUOG4GFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_midi(new_tune, rhythms=tune_rand_rhythm)"
      ],
      "metadata": {
        "id": "D5l33ptbEvqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll get better results if we design a separate Markov model for rhythm that accounts for how note durations tend to work in real music.\n",
        "\n",
        "The `rhythm_model` below is set up just like the pitch model, and I've made some semi-reasonable choices in designing it (e.g. the shortest duration, 0.5, is most likely to be followed by another 0.5, so that together they fill the space of a single 1.0 duration). It isn't required, but *feel free to modify this model*.\n",
        "\n",
        "**Your exercise is to complete the `generate_rhythms()` function below.** The function should return a list of durations of the same length as the rune that's also provided as an argument.\n",
        "\n",
        "The code will be similar to the generator functions for previous models, but requires a couple decisions about how to start new sequences, and how to control the length of the duration sequence since it needs to be the same as the tune."
      ],
      "metadata": {
        "id": "LpVwz80mU3aD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rhythm_model = { # Feel free to modify this\n",
        "    0.5: {0.5: 0.8, 1: 0.2},\n",
        "    1: {1: 0.5, 0.5: 0.1, 2: 0.4},\n",
        "    2: {1: 0.5, 2: 0.3, 4: 0.2},\n",
        "    3: {0.5: 0.4, 1: 0.6},\n",
        "    4: {1: 1}\n",
        "}\n",
        "\n",
        "def generate_rhythms(tune, r_model):\n",
        "    rhythms = []\n",
        "    # your code here\n",
        "    return rhythms"
      ],
      "metadata": {
        "id": "A9QXSOk-BCnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_rhythms = generate_rhythms(new_tune, rhythm_model)\n",
        "play_midi(new_tune, rhythms=generated_rhythms)"
      ],
      "metadata": {
        "id": "ml1JmQXr_I1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra credit: Interval-based model"
      ],
      "metadata": {
        "id": "cPjR993mIZ9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've previously seen examples of higher-order models that take more than one pitch as the current model state, which tend to produce outputs that feel less random over longer outputs.\n",
        "\n",
        "When generating melodies, we can approximate the idea of a higher-order model without actually constructing states from multiple tokens by using a trick: we can generate melodies in terms of **intervals** rather than individual notes.\n",
        "\n",
        "An interval by definition consists of two notes, so by naming a single interval, like `5`, we automatically represent two pitches a fifth apart.\n",
        "\n",
        "But since we're working in diatonic space rather than pitch class space, intervals have to be calculated using \"musical math\"---the notes `'=1'` and `'=3'` are separated by a *third*, even though they are two steps apart.\n",
        "\n",
        "**To begin the extra credit assignment, fill out this function** that takes in the `keyboard` that we created earlier, a current pitch (e.g. `'-7'` or `'=5'`), and an interval (a simple integer). It should return the diatonic scale degree that results from applying the interval to the current pitch.\n",
        "\n",
        "For example, `pitch_from_interval(keyboard, '=7', 4)` should return `'+3'`."
      ],
      "metadata": {
        "id": "njLYNitCjAqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pitch_from_interval(keyboard, cur_pitch, interval):\n",
        "    # your code here"
      ],
      "metadata": {
        "id": "Qorupyg_JVTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pitch_from_interval(keyboard, '=7', 4)"
      ],
      "metadata": {
        "id": "xEAXZi7WKE3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now try out the following two cells, which build a simple interval model and then generate tunes and rhythms from it. This will only work if you've completed the `pitch_from_interval()` function above.\n",
        "\n",
        "The default model only allows for very simple melodic motion: taking a step up or down, staying on the same note, or moving up by third.\n",
        "\n",
        "**To complete the extra credit portion, expand the interval model to allow for other melodic possibilities.** Specifically, make sure that it's possible to leap up and down by fourth, fifth, and sixth. Your model should take account of the fact that in most tonal melodies, large leaps are most often (but not always) followed by a step (movement by second) in the opposite direction.\n",
        "\n",
        "Finally, the `generate_from_intervals()` function produces a new melody using the interval model, but it's set to end the melody as soon as scale degree 1 appears for the first time. This is not ideal because, as we've seen, it's possible to have scale degree 1 appear in a melody without being the final note.\n",
        "\n",
        "**To complete the extra credit portion, modify this condition so that melodies still always end on scale degree 1, but so that they don't automatically end the first time it appears.**"
      ],
      "metadata": {
        "id": "MS5hKiChUhD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interval_model = { # expand this model\n",
        "    -2: {-2: 0.5, 1: 0.3, 3: 0.2},\n",
        "    1: {1: 0.2, 2: 0.3, -2: 0.5},\n",
        "    2: {2: 0.5, -2: 0.5},\n",
        "    3: {3: 0.5, -2: 0.3, -2: 0.2},\n",
        "}\n",
        "\n",
        "def generate_from_intervals(i_model, start_pitch):\n",
        "    intervals = []\n",
        "    final_tune = start_pitch\n",
        "    current_int = random.choice([-2, 1, 2, 3])\n",
        "    generating = True\n",
        "    while generating:\n",
        "        intervals.append(current_int)\n",
        "        current_int = next_state(interval_model, current_int)\n",
        "        next_pitch = pitch_from_interval(keyboard, final_tune[-2:], current_int)\n",
        "        final_tune += ' ' + next_pitch\n",
        "        if next_pitch[1] == '1': # improve this end condition\n",
        "            generating = False\n",
        "\n",
        "    return final_tune"
      ],
      "metadata": {
        "id": "7d4qR2bWKKqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell will use the rhythm model from earlier to supplement the new interval-based melodies."
      ],
      "metadata": {
        "id": "VITt0CRfgXQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interval_tune = generate_from_intervals(interval_model, '=3')\n",
        "generated_rhythms = generate_rhythms(interval_tune, rhythm_model)\n",
        "play_midi(interval_tune, rhythms=generated_rhythms)"
      ],
      "metadata": {
        "id": "PpOOd8zNO3W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ACUJQBpbO6Jh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}